
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>CIFAR-10 on Tensorflow - Life Matrix</title>
  <meta name="author" content="Steven Liu <stevenliucx@gmail.com>&#8221;>

  
  <meta name="description" content="CIFAR-10 数据集 CIFAR-10和CIFAR-100是对象识别的基准数据集。它们是从8000万微型图片数据集选取的子集。CIFAR-10中包含60000张32x32的彩色图片，分为10类，即每类有6000张。其中50000张作为训练集，另10000张为训练集。 这10类分别是： &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://hack.the-lifematrix.net/blog/2016/02/cifar10-on-tensorflow">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Life Matrix" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  


  <!-- mathjax config similar to math.stackexchange -->
  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       jax: ["input/TeX", "output/HTML-CSS"],
       tex2jax: {
          inlineMath: [ ['$', '$'] ],
          displayMath: [ ['$$', '$$']],
          procehssEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
       },
       messageStyle: "none",
       "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
     });
   </script>
   <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Life Matrix</a></h1>
  
    <h2>Hacking, Machine learning, Lisp</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:hack.the-lifematrix.net" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/resources">Resources</a></li>
  <li><a href="/lisp-resource">Lisp Resource</a></li>
  <li><a href="/resources-on-deep-learning">Deep Learning</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">CIFAR-10 on Tensorflow</h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-02-18T16:39:12+08:00'><span class='date'><span class='date-month'>Feb</span> <span class='date-day'>18</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>4:39 pm</span></time>
        
      </p>
    
  </header>


<div class="entry-content"><h2 id="cifar-10-">CIFAR-10 数据集</h2>

<p><a href="http://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10和CIFAR-100</a>是对象识别的基准数据集。它们是从<a href="http://groups.csail.mit.edu/vision/TinyImages/">8000万微型图片数据集</a>选取的子集。CIFAR-10中包含60000张32x32的彩色图片，分为10类，即每类有6000张。其中50000张作为训练集，另10000张为训练集。</p>

<p>这10类分别是：airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck，示例如下：</p>

<p><img src="http://hack.the-lifematrix.net/images/cifar10-tf/cifar10_sample.png" alt="" /></p>

<p>这类是互斥的，也即：每个图片唯一属于某类。</p>

<p>而CIFAR-100数据集和CIFAR-10类似，但是分为100个类。这100个类又属于20个父类。</p>

<h2 id="tensorflow">Tensorflow</h2>

<p><a href="www.tensorflow.org">Tensorflow</a>是google去年年底刚刚公开的深度学习计算框架。虽然在一些比较中(<a href="http://fastml.com/what-you-wanted-to-know-about-tensorflow/">fastml</a>, <a href="https://github.com/soumith/convnet-benchmarks/issues/66">soumith</a>, <a href="http://chenrudan.github.io/blog/2015/11/18/comparethreeopenlib.html">陈汝丹</a>)，tensorflow的计算速度比caffe等要慢很大。但是tensorflow的优势，如其<a href="http://download.tensorflow.org/paper/whitepaper2015.pdf">白皮书</a>所言，在于其架构。它提供了跨域异构计算资源(从移动设备、单机到多GPU集群…)的一致性计算平台，其抽象能力和扩展性极其优越，极大降低开发、运行和维护的成本。Google对计算架构的理解和设计有超乎寻常的远见，比如Google的三驾马车GFS、Map-Reduce、BigTable开启了大数据计算框架之先河。所以tensorflow计算慢的问题，相信其设计者应该意识到的，今后或许有改进。总之，值得对tensorflow做些探索和学习。</p>

<p>虽然tensforflow的文档还不够丰富，但它的确提供了采用cifar-10数据集的<a href="https://www.tensorflow.org/versions/r0.7/tutorials/deep_cnn/index.html">示例程序</a>。也许，为了充分说明tensorflow的各种特色：并发性、多GPU处理等，所以，这个代码结构对于初学者过于复杂，而且模型的构造淹没在很多代码细节中，不够清晰。因此，笔者决定自己探索实现一个程序。</p>

<h2 id="section">基本模型</h2>

<p>UC Berkeley <a href="http://caffe.berkeleyvision.org">Caffe</a>计算框架中，用配置文件的方式来定义模型，独立于代码，因此模型的定义很清晰也易于调整。本文就选择了其中的<a href="https://github.com/BVLC/caffe/blob/master/examples/cifar10/cifar10_quick.prototxt">快速示例</a>，作为基本模型，再逐步调优。</p>

<p><img src="http://hack.the-lifematrix.net/images/cifar10-tf/cifar10_model_basic.png" alt="" width="400px" /></p>

<p>由于训练集数据不算大(几百兆)，可以一次性全部读入内存，以下测试时给出的运行时间，就不包含读取图片的时间。</p>

<p>基本模型的运行情况(batchsize=100)：</p>

<p><img src="http://hack.the-lifematrix.net/images/cifar10-tf/time_basic.png" alt="" /></p>

<p>最大正确校验正确率：73.08%，在epoch=30, 训练100分钟时达到。之后更多的训练没有提高正确率。</p>

<h3 id="random-crop">Random Crop</h3>

<p>深度网络的参数巨大，很容易出现过拟合。通过人为扩大训练集数据(<a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">ImageNet</a>)，是避免过拟合的有效策略。先尝试简单的方法，在32x32的图片中，随机裁剪出28<em>28的图片，进行训练。这也就是将训练集扩大了4</em>4=16倍。</p>

<p><img src="http://hack.the-lifematrix.net/images/cifar10-tf/time_randomcrop.png" alt="" /></p>

<p>最大正确校验正确率：74.58%，在epoch=56, 训练137分钟时达到。之后更多的训练没有提高正确率。</p>

<p>正确性叫基本模型提高了1.5个百分点，效果明显。</p>

<h3 id="dropout">Dropout</h3>

<p>Dropout也是一种变相的调整策略，避免过拟合(<a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">ImageNet</a>)。要注意的是，在训练是采用dropout(keep_prob=0.5), 但是在validation时则不选用(keep_prob=1.0)。</p>

<p><img src="http://hack.the-lifematrix.net/images/cifar10-tf/time_dropout.png" alt="" /></p>

<p>最大正确校验正确率：76.22%，在epoch=103, 训练260分钟时达到。之后更多的训练没有提高正确率。
又提高了1.64%个百分点。可见有明显的效果。</p>

<p>在<a href="https://www.kaggle.com/c/cifar-10">Kaggle的cifar10竞赛</a>中得分为：74.59%。</p>

<p><img src="http://hack.the-lifematrix.net/images/cifar10-tf/kaggle_dropout.png" alt="" /></p>

<h3 id="section-1">内存使用分析</h3>

<p>受<a href="http://cs231n.github.io/convolutional-networks/">此文</a>对<a href="http://www.robots.ox.ac.uk/%7Evgg/research/very_deep/">VGGNet</a>分析的启发，也对本例的简单模型做类似分析。注意，由于采用了crop，则较前图的基本模型，图片输入为28*28像素。后面的数据维度也相应调整。</p>

<table>
  <thead>
    <tr>
      <th>Layer</th>
      <th>Data Shape</th>
      <th>Data Memory</th>
      <th>Weights</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Input Layer</td>
      <td>28*28@3</td>
      <td>9K</td>
      <td>0</td>
    </tr>
    <tr>
      <td>Conv-1 (5x5@32)</td>
      <td>28*28@32</td>
      <td>98K</td>
      <td>5<em>5</em>3*32+32 = 2,432</td>
    </tr>
    <tr>
      <td>MaxPool-1</td>
      <td>14*14@32</td>
      <td>25K</td>
      <td>0</td>
    </tr>
    <tr>
      <td>Conv-2 (5x5@32)</td>
      <td>14*14@32</td>
      <td>25K</td>
      <td>5<em>5</em>32*32+32 = 25,632</td>
    </tr>
    <tr>
      <td>AvgPool-2</td>
      <td>7*7@32</td>
      <td>6K</td>
      <td>0</td>
    </tr>
    <tr>
      <td>Conv-3 (5x5@64)</td>
      <td>7*7@64</td>
      <td>12K</td>
      <td>5<em>5</em>32*64 = 51,200</td>
    </tr>
    <tr>
      <td>Relu-3</td>
      <td>7*7@64</td>
      <td>12K</td>
      <td>0</td>
    </tr>
    <tr>
      <td>AvgPool-3</td>
      <td>4*4@64</td>
      <td>4K</td>
      <td>0</td>
    </tr>
    <tr>
      <td>FC Layer-4</td>
      <td>64</td>
      <td> </td>
      <td>1024*64 + 64 = 65,600</td>
    </tr>
    <tr>
      <td>FC Layer-5</td>
      <td>10</td>
      <td> </td>
      <td>64*10 + 10 = 640</td>
    </tr>
  </tbody>
</table>

<p>*注：每个数字用float32存储，占4个字节。卷积网络的一个特点就是，数据类型的精度对训练结果影响不大。参见: <a href="http://arxiv.org/abs/1502.02551">Deep Learning with Limited Numerical Precision</a>, <a href="https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf">Learning Multiple Layers of Features from Tiny Images</a></p>

<p>每个实例的数据，需要内存191K。共有142K(145,504)个参数，需要内存142K*4=568K。</p>

<p>假设GPU内存有4G，一次性处理的最大batchsize:
 (4G - 568K) / 191K = 21956</p>

<h3 id="section-2">时间分析</h3>

<p>花了4个小时才训练出最优的模型，一方面是算法问题，也与tensorflow固有的较低的计算速度有关。</p>

<h3 id="batchsize">Batchsize</h3>

<p>如果batchsize=1000, 明显看出学习速度明显下降。花费近8个小时，训练的最好模型的校验正确率为72.10%。</p>

<p><img src="http://hack.the-lifematrix.net/images/cifar10-tf/batchsize1000.png" alt="" /></p>

<p>如果batchsize=200, 学习速率也有些慢。花费4个小时，达到最高的校验正确率75.82%。但学习过程似乎不够稳定。
<img src="http://hack.the-lifematrix.net/images/cifar10-tf/batchsize200.png" alt="" /></p>

<p>或许要调整一下学习率</p>

<h2 id="section-3">更深的网络</h2>

<p>上述基本网络只用了3个卷积层，达到75%的正确率，换言之25%的错误率。结果不是很出色，<a href="https://github.com/nagadomi/kaggle-cifar10-torch7">Torch 7 ConvNet</a> 取得了7%的错误率。决定在tensorflow下实验此模型。结果，请见后文。</p>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Steven Liu <stevenliucx@gmail.com></span></span>

      




<time class='entry-date' datetime='2016-02-18T16:39:12+08:00'><span class='date'><span class='date-month'>Feb</span> <span class='date-day'>18</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>4:39 pm</span></time>
      


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://hack.the-lifematrix.net/blog/2016/02/cifar10-on-tensorflow/" data-via="" data-counturl="http://hack.the-lifematrix.net/blog/2016/02/cifar10-on-tensorflow/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2016/01/value-websites-in-book-exponential-organization/" title="Previous Post: 《指数型组织》中提到的网站">&laquo; 《指数型组织》中提到的网站</a>
      
      
        <a class="basic-alignment right" href="/blog/2016/02/face-analysis/" title="Next Post: face analysis">face analysis &raquo;</a>
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2016/04/how-to-make-mac-os-write-ntfs-volume/">Mac系统下如何让NTFS磁盘卷可写</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/04/notes-on-how-google-works-1/">《谷歌如何运作》笔记一：前言</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/03/rsa-and-implemenation-by-self-in-python/">RSA and Implemenation by Self in Python</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/03/chaos-communication-congress-a-very-german-hacking-conference/">混沌通讯会议：一场很德国的黑客大会</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/02/face-analysis/">Face Analysis</a>
      </li>
    
  </ul>
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - Steven Liu <stevenliucx@gmail.com> -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
